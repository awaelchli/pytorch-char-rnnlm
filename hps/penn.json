{
    "train_corpus": "./data/penn/train.txt",
    "eval_corpus": "./data/penn/valid.txt",
    "test_corpus": "./data/penn/test.txt",
    "tokenization": "char",
    "vocab_file": "./model/penn/vocab_file.json",
    "save": "./model/penn/pytorchmodel",
    "emsize": 1000,
    "nhid": 1000,
    "nlayers": 2,
    "dropout": 0.5,
    "tied": true,
    "batch_size": 100,
    "bptt": 35,
    "clip": 0.25,
    "log_interval": 1000,
    "lr": 3.0,
    "epochs": 100,
    "cuda": true
}
